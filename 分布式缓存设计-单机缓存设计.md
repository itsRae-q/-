# 分布式缓存
### 介绍
    高并发环境下，短时间内流量很高，如果让大量的读写请求直接访问数据库，由于磁盘的处理速度与内存显然不在一个量级，服务器马上就要宕机。为了减轻数据库的压力和提高系统响应速度，会在数据库之前加一层缓存，将数据存放在内存中，减轻数据库压力，提高响应速度。
    
    由于单台机器的内存资源以及承载能力有限，如果大量使用本地缓存，也会使相同的数据被不同的节点存储多份，对内存资源造成较大的浪费，因此，需要采用分布式缓存。

    目前常用的分布式缓存有redis,Memcache等
    
    分布式缓存常见问题：
    缓存雪崩，缓存穿透，缓存预热，缓存更新等
    
### 设计思路
    学习GroupCache,设计实现一个简单的分布式缓存系统
    
    特点：
    与Redis等不同，此次实现的缓存系统不是单独的服务，而是和业务服务运行在同一进程中，即作为服务端处理请求，也作为客户端向其他节点发送缓存查询的请求。
    
    
### 主体架构

![image](https://user-images.githubusercontent.com/46525758/138409767-1d2bf23a-8a7e-474d-a3a8-997a7c732624.png)

    主要思路：
    整个系统的核心部分就是groupcacache.Group这一个struct，负责了cache的本地查询和远程节点选择查询，当某个key在本地找不到时，groupcacache会基于一致性哈希计算远程节点，向对应节点发送HTTP request，当cache在本地和peer都不存在时，它便会调用指定的回调函数从DB读取数据进行缓存
    
    缓存基于LRU实现数据的淘汰，采用加锁实现对缓存的并发写入和查询
    
### 主要模块
    1.LRU单机缓存
    2.并发安全的单机缓存
    3.基于HTPP/RPC通信的分布式缓存
    4.一致性哈希的分布式节点选择
    5.缓存击穿优化
    。。。
    
### LRU单机缓存
    当缓存值达到指定内存阈值时，需要将部分缓存进行移除，主要策略有FIFO(First In First Out)，LFU(Least Frequently Used)，LRU(Least Recently Used)等，本系统基于LRU实现对缓存数据的淘汰
    
    LRU 认为，如果数据最近被访问过，那么将来被访问的概率也会更高。通过维护一个队列，将最近被访问到的数据放在队首，每次需要删除缓存时，淘汰队尾的记录即可。
    
    LRU核心数据结构包含一个双向列表及一个Map
    
    其中双向列表用于实现对缓存数据的移动(移到队首)及删除，时间复杂度是O(1)，采用双向链表而不是单向链表的目的是高效删除队尾元素
    
    Map键存Key, Value存双向链表节点的指针，用于实现根据Key删除缓存值，复杂度O(1)

![image](https://user-images.githubusercontent.com/46525758/138409800-5fc10177-a028-443c-8829-f6adf068ae49.png)

    LRU主要数据结构：
        
```go
type Cache struct {
	m             map[string]*list.Element
	ll            *list.List // value is entry
	usedBytes     int64
	maxBytes      int64
	deleteHandler DeleteHandler
}

type entry struct {
	k string
	v Value
}

type Value interface {
	Len() int64
}

type DeleteHandler func(k string, v Value)


func (c *Cache) Get(k string) (Value, bool)

func (c *Cache) Add(k string, v Value)

func (c *Cache) Delete(k string)

func NewCache(maxBytes int64, f DeleteHandler) *Cache
```

    Cache是LRU缓存实体，其中
    m中key存缓存查询值，value存链表节点指针
    ll为双向链表
    usedBytes---已使用内存
    maxBytes---缓存最大可用内存
    deleteHandler---回调函数，在缓存记录移除时进行调用
    
    entry链表节点值，k为缓存查询值，用于移除队尾节点时删除map中元素，v为缓存值，类型为实现了Len()方法的interface
    
    Cache提供了查询，添加，删除及初始化LRU的接口
    
### 单机并发缓存
    通过加锁实现对LRU协程安全的并发更新及查询操作
    
    主要数据结构：
    
    
```go
type ConcurrentCache struct {
	mu       *sync.Mutex
	cache    *lru.Cache
	maxBytes int64
}

func (c *ConcurrentCache) Add(k string, v ByteView) 

func (c *ConcurrentCache) Delete(k string)

func (c *ConcurrentCache) Get(k string) (ByteView, bool) 

```

    基于LRU的接口对Get,Delete,Add进行了加锁封装，实现并发安全的读写，对缓存值封装为ByteView，只读，并提供了拷贝方法
    
    
```go
type ByteView struct {
	b []byte
}

func (b ByteView) Len() int64

func (b ByteView) Clone() []byte

```

    定义Group,实现与用户的交互，暴露Add,Get,Delete接口及初始化方法。
    不同Group存储不同数据，例如配置表缓存数据，UID缓存数据等
    
```go
type GroupCache struct {
	name       string
	groupCache *ConcurrentCache
	getter     Getter
}

type Getter interface {
	Get(k string) ([]byte, error)
}

type GetterFunc func(k string) ([]byte, error)

func (g GetterFunc) Get(k string) ([]byte, error) {
	return g(k)
}
```
    name为Group名字
    
    groupCache为并发安全的LRU
    
    定义getter接口，包含Get函数，用于无缓存数据时从本地获取缓存数据的方法
    
    定义了一个接口 Getter，只包含一个方法 Get(key string) ([]byte, error)，紧接着定义了一个函数类型 GetterFunc，GetterFunc 参数和返回值与 Getter 中 Get 方法是一致的。而且 GetterFunc 还定义了 Get 方式，并在 Get 方法中调用自己，这样就实现了接口 Getter
    
    定义接口型函数GetterFunc，好处是扩展性较强，初始化Group的时候即可以传入GetterFunc 类型的函数作为参数，也可以传入实现了接口的结构体，类似net/http 的 Handler 和 HandlerFunc
    
